daemon off;
worker_processes auto;
pid /var/lib/hypothesis/nginx.pid;
error_log /dev/stderr;

# This file handle limit should ideally by the number of worker 
# connections * 2. But it can't exceed the "hard" limit applied 
# by the OS. Which for the moment is 4096 in our deploys.
worker_rlimit_nofile 4096;

events {
  worker_connections 4096;
}

http {
  client_max_body_size 20m;
  sendfile on;
  server_tokens off;

  include mime.types;
  default_type application/octet-stream;

  access_log off;

  # If there is an auth token, rate limit based on that,
  # else if there is a cloudflare ip header rate limit based on that,
  # otherwise assume it's from an internal service and do not
  # rate limit at all.
  map $http_authorization $limit_per_user {
    "" $http_cf_connecting_ip;
    default $http_authorization;
  }

  # 1m stands for 1 megabyte so the zone can store ~8k users.
  # User's typically don't go over 1rps including bots so set the
  # generic rate limit of all endpoints to 1rps.
  limit_req_zone $limit_per_user zone=badge_user_1rps_limit:1m rate=1r/s;
  limit_req_zone $limit_per_user zone=assets_user_1rps_limit:1m rate=1r/s;
  limit_req_zone $limit_per_user zone=create_ann_user_1rps_limit:1m rate=1r/s;
  limit_req_zone $limit_per_user zone=user_1rps_limit:1m rate=1r/s;
  limit_req_status 429;

  # We set fail_timeout=0 so that the upstream isn't marked as down if a single
  # request fails (e.g. if gunicorn kills a worker for taking too long to handle
  # a single request).
  upstream web { server unix:/tmp/gunicorn-web.sock fail_timeout=0; }
  upstream websocket { server unix:/tmp/gunicorn-websocket.sock fail_timeout=0; }

  server {
    listen 5000;

    server_name _;
    server_tokens off;

    root /var/www;

    location /ws {
      proxy_pass http://websocket;
      proxy_http_version 1.1;
      proxy_redirect off;
      proxy_buffering off;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection upgrade;
      proxy_set_header Host $host;
      proxy_set_header X-Forwarded-Server $http_host;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /annotating-all-knowledge/ {
      proxy_pass https://hypothesis.github.io;
      proxy_http_version 1.1;
      proxy_set_header Host $proxy_host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /roadmap {
      return 302 "https://github.com/hypothesis/product-backlog/projects/6";
    }

    location @api_error_429 {
        return 429 '{"status": "failure", "reason": "Request rate limit exceeded"}';
    }

    location / {
      proxy_pass http://web;
      proxy_http_version 1.1;
      proxy_connect_timeout 10s;
      proxy_send_timeout 10s;
      proxy_read_timeout 10s;
      proxy_redirect off;
      proxy_set_header Host $host;
      proxy_set_header X-Forwarded-Server $http_host;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Request-Start "t=${msec}";

      # The /api/badge endpoint limit is chosen to limit the
      # load from any single user, and take advantage of latency
      # not being critical.
      location /api/badge {
        limit_req zone=badge_user_1rps_limit burst=15;
        error_page 429 @api_error_429;

        proxy_pass http://web;
      }

      # The /assets rate limit is chosen so that the user
      # can refresh the web page with the most asset links
      # on it a few times in succession without hitting the
      # limit.
      location /assets {
        limit_req zone=assets_user_1rps_limit burst=139 nodelay;

        proxy_pass http://web;
      }

      # The POST /api/annotations limit is chosen to allow
      # reasonable usage while preventing a single user from
      # causing service disruption.
      location =/api/annotations {
        limit_req zone=create_ann_user_1rps_limit burst=8;
        error_page 429 @api_error_429;

        proxy_pass http://web;
      }

      location /api {
        limit_req zone=user_1rps_limit burst=44 nodelay;
        error_page 429 @api_error_429;

        proxy_pass http://web;
      }

      # An overall rate limit was chosen to allow reasonable usage while
      # preventing a single user from causing service disruption.
      limit_req zone=user_1rps_limit burst=44 nodelay;
    }
  }

  server {
    listen 127.0.0.234:5000;
    server_name _;

    location /status {
      stub_status on;
      access_log off;
      allow 127.0.0.0/24;
      deny all;
    }
  }
}
